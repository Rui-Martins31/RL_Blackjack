\begin{lstlisting}[caption={Easy21 Environment Class Initialization}, label={listing:class_easy21}, float=h!]
class Easy21:
    def __init__(self):

        # Observations
        self.cards_dealer: list[int] = []   # First card: 1-10
        self.cards_player: list[int] = []   # Total sum: 1-21

        # Actions
        self.actions: list[str] = [STICK, HIT]    # Stick, Hit

        # Probabilities
        self.draw_values: tuple[int] = (1, 10) # If we draw a red card we have (-10, -1) instead
        self.prob_red: float    = 1/3
        self.prob_black: float  = 2/3
\end{lstlisting}

\begin{lstlisting}[caption={Agent Class Initialization}, label={listing:class_agent}][h]
class Agent:
    def __init__(
            self,
            observation: tuple[int] = _config.SCENARIO_OBSERVATIONS,
            num_observations: tuple[int] = _config.SCENARIO_OBSERVATIONS_NUM,
            actions: tuple[int] = _config.SCENARIO_ACTIONS,
            num_actions: int = _config.SCENARIO_ACTIONS_NUM,
            alpha: float = _config.ALPHA,
            gamma: float = _config.GAMMA, 
            epsilon: float = _config.EPSILON,
            epsilon_decay_factor: float = _config.EPSILON_DECAY_FACTOR,
            epsilon_min: float = _config.EPSILON_MIN
        ):

        # Info
        self.prev_observation  = observation
        self.num_observations  = num_observations

        self.actions           = actions
        self.num_actions       = num_actions

        # Current state
        # Q-matrix shape: (num_actions, player_sum, dealer_card)
        self.q_matrix          = np.zeros((self.num_actions, *self.num_observations))
        self.is_training: bool = False

        # Training
        self.epsilon: float       = epsilon
        self.epsilon_decay_factor = epsilon_decay_factor
        self.epsilon_min: float   = epsilon_min
        self.lr: float            = alpha
        self.gamma: float         = gamma
\end{lstlisting}

\begin{lstlisting}[caption={Configuration File}, label={listing:config_file}][h]
# Scenario
SCENARIO_OBSERVATIONS: tuple[int]     = (0, 0)
SCENARIO_OBSERVATIONS_NUM: tuple[int] = (10+1, 10+1) #(21+1, 21+1)         # +1 is the offset since array starts at [0]
SCENARIO_ACTIONS: tuple[int]          = (0, 1)
SCENARIO_ACTIONS_NUM: int             = len(SCENARIO_ACTIONS)

# Agent
AGENT_TRAIN: bool = True

# Episode
if AGENT_TRAIN: 
    NUM_EPISODES: int = 1_000_000
else:
    NUM_EPISODES: int = 10_000

# Training
EPSILON: float              = 1.0
EPSILON_DECAY_FACTOR: float = 0.99
EPSILON_MIN: float          = 0.1
ALPHA: float                = 0.1    # Learning Rate
GAMMA: float                = 0.99   # Discount Factor

# Path
PATH_SAVE_IMAGES: str   = "model/images/"
PATH_SAVE_Q_MATRIX: str = "model/q_matrix/"
\end{lstlisting}